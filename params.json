{"name":"Baxter Builds a Tower","tagline":"Using a Baxter Robot with AR Tags to stack blocks into a Tower","body":"Markdown reference\r\nProject Guidelines\r\n\r\n# Introduction\r\nIn **Baxter Builds a Tower**, the end goal is to allow a [Baxter robot] (http://www.rethinkrobotics.com/) to autonomously pick up toy blocks in any desired order and then stack them vertically to create a tower.\r\n\r\n**Baxter Builds a Tower** is an interesting project because it combines both robust computer vision and good kinematics/path planning for success. In our traditional mechanical engineering training, we often deal with the latter instead of the former. Therefore, **Baxter Builds a Tower** is a very attractive project for us because we get the rare chance to work in both realms of robotics at once. In the course of this project, we had to overcome the limitations of off the shelf computer vision packages as well as the hardware limitations in Baxter’s end effector accuracy. In later sections, we will detail how we overcame these obstacles.\r\n\r\nThe work developed in this project can be useful in car junkyards when cars arrive and need to be stacked/stored. Upon further extension, the work here can also aid in assembly line quality assurance tasks, such as removing defective products from an assembly line and storing them in a separate location for further processing. More importantly, Baxter playing with toy blocks is a great boon towards promoting STEM to the younger audience.\r\n\r\n\r\n# Design\r\n## Criterias\r\n* Identify toy blocks through computer vision\r\n* Retrieve toy blocks with robotic arm\r\n* Place toy blocks down and successively stack blocks vertically into a tower\r\n* Repeat\r\n* **Baxter will autonomously pick up many toy blocks and successively stack them to make a tower**\r\n\r\nTo achieve the above, we decided to use [AR Tags](http://wiki.ros.org/ar_track_alvar) and [ROS MoveIt](http://moveit.ros.org/) pathplanner in order to manipulate toy blocks conveniently sold in various toy stores. We decided to use AR Tags to simplify the task of computer vision, but at the expense of only manipulating objects with large planar faces that can support an AR Tag. Moreover, we had to use cameras located on Baxter’s hand in order to perceive the toy blocks because the head-mounted camera is too far away to accurately detect AR Tags. Consequently, the robot workspace decreased accordingly because of the camera’s decreased field of view. Finally, we intelligently selected the location of toy blocks and arm motion trajectory to minimize the chance of toy block to robot collisions. By doing so, we can avoid importing CAD models of the environment to RVIZ  and save on computation time in path planning.\r\n\r\nThe simplifying design choices made here probably would not suffice in the real world. The decision to use AR Tags definitely constrains the realistic sizes of objects we can manipulate with. Moreover, using hand-mounted cameras, instead of head-mounted or externally mounted, cameras definitely limits the workspace and forces us to be tied to platforms, like Baxter, with hand-mounted cameras. Finally, not allowing Baxter to be cognizant of its environment means that environments would have to be highly controlled and largely static, characteristics that are too idealized compared to the real world.\r\n\r\n# Implementation\r\n＃System Introduction\r\nHardware:\r\nBaxter\r\nBaxter is a human form and proportional robot with two 7-degree-of-freedom arms. It\r\nalso has a good vision-guided capability to detect/recognize objects in the workspace.\r\nThus, it has several nice features to implement our task.\r\nBuilding Blocks\r\nBuilding bricks are wooden, plastic or foam pieces of various shapes (square,\r\ncylinder,arch, triangle, etc.) and colors that are used as construction toys. In our project, it\r\nis the construction materials to build a house.\r\nARTag\r\nARTag is a fiduciary marker system to support augmented reality. It can be used to make\r\nit easy to make virtual objects, games, and animations appear to enter the real world. Like\r\nthe earlier ARToolKit system, it allows for video tracking capabilities that calculate the\r\nreal camera position and orientation relative to square physical markers in real time.\r\n\r\nSoftware:\r\nROS\r\nThe Robot Operating System (ROS) is a flexible framework for writing robot software. It\r\nis a collection of tools, libraries, and conventions that aim to simplify the task of creating\r\ncomplex and robust robot behavior across a wide variety of robotic platforms.\r\n\r\n\r\n\r\nIf you prefer to not use the automatic generator, push a branch named `gh-pages` to your repository to create a page manually. In addition to supporting regular HTML content, GitHub Pages support Jekyll, a simple, blog aware static site generator written by our own Tom Preston-Werner. Jekyll makes it easy to create site-wide headers and footers without having to copy them across every page. It also offers intelligent blog support and other advanced templating features.\r\n\r\n# Results\r\n\r\n\r\n# Conclusion\r\nHaving trouble with Pages? Check out the documentation at https://help.github.com/pages or contact support@github.com and we’ll help you sort it out.\r\n\r\n# Team\r\nHaving trouble with Pages? Check out the documentation at https://help.github.com/pages or contact support@github.com and we’ll help you sort it out.\r\n\r\n# Additional Materials\r\nHaving trouble with Pages? Check out the documentation at https://help.github.com/pages or contact support@github.com and we’ll help you sort it out.\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}