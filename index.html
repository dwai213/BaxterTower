
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Baxter Builds a Tower by ucbBaxterTower</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>Baxter Builds a Tower</h1>
        <p>Using a Baxter Robot with AR Tags to stack blocks into a Tower</p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://github.com/ucbBaxterTower/BaxterTower" class="button fork"><strong>View On GitHub</strong></a>
        <div class="downloads">
          <span>Downloads:</span>
          <ul>
            <li><a href="https://github.com/ucbBaxterTower/BaxterTower/zipball/master" class="button">ZIP</a></li>
            <li><a href="https://github.com/ucbBaxterTower/BaxterTower/tarball/master" class="button">TAR</a></li>
          </ul>
        </div>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h1>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h1>

<p>In <strong>Baxter Builds a Tower</strong>, the end goal is to allow a <a href="http://www.rethinkrobotics.com/">Baxter robot</a> to autonomously pick up toy blocks in any desired order and then stack them vertically to create a tower.</p>
<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/tower1.jpg" alt="Toy blocks being stacked" width="304" height="228" align="middle">
  <figcaption>Go Bears!</figcaption>
</figure>
</div>
<br>
<p><strong>Baxter Builds a Tower</strong> is an interesting project because it combines both robust computer vision and good kinematics/path planning for success. In our traditional mechanical engineering training, we often deal with the latter instead of the former. Therefore, <strong>Baxter Builds a Tower</strong> is a very attractive project for us because we get the rare chance to work in both realms of robotics at once. In the course of this project, we had to overcome the limitations of off the shelf computer vision packages as well as the hardware limitations in Baxter’s end effector accuracy. We will discuss these issues in great detail in later sections.</p>

<p>The work developed in this project can be useful in car junkyards when cars arrive and need to be stacked/stored. Upon further extension, the work here can also aid in assembly line quality assurance tasks, such as removing defective products from an assembly line and storing them in a separate location for further processing. More importantly, Baxter playing with toy blocks is a great boon towards promoting STEM to the younger audience.</p>

<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/tower2.jpg" alt="Image courtesy of rethinkrobotics" width="500" height="276" align="middle">
  <figcaption>Kids interacting with Baxter</figcaption>
</figure>
</div>
<br>
<h1>
<a id="design" class="anchor" href="#design" aria-hidden="true"><span class="octicon octicon-link"></span></a>Design</h1>

<h3>
<a id="criterias" class="anchor" href="#criterias" aria-hidden="true"><span class="octicon octicon-link"></span></a>Criterias</h3>

<ul>
<li>Identify toy blocks through computer vision</li>
<li>Retrieve toy blocks with robotic arm</li>
<li>Place toy blocks down and successively stack blocks vertically into a tower</li>
<li>Consistenyl repeatable</li>
<li><strong>Baxter will autonomously pick up many toy blocks and successively stack them to make a tower</strong></li>
</ul>

<p>To achieve the above, we decided to use <a href="http://wiki.ros.org/ar_track_alvar">AR Tags</a> and <a href="http://moveit.ros.org/">ROS MoveIt</a> pathplanner in order to manipulate toy blocks conveniently sold in various toy stores. We decided to use AR Tags to simplify the task of computer vision, but at the expense of only manipulating objects with large planar faces that can support an AR Tag. Moreover, we had to use cameras located on Baxter’s hand in order to perceive the toy blocks because the head-mounted camera is too far away to accurately detect AR Tags. Consequently, the robot workspace decreased accordingly because of the camera’s decreased field of view. Finally, we intelligently selected the location of toy blocks and arm motion trajectory to minimize the chance of toy block to robot collisions. By doing so, we can avoid importing CAD models of the environment to RVIZ  and save on computation time in path planning.</p>

<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/tower3.jpg" alt="Baxter and toy blocks in our workspace" width="300" height="400" align="middle">
  <figcaption>Baxter and toy blocks in our workspace</figcaption>
</figure>
</div>
<br>
<p>The simplifying design choices made here probably would not suffice in the real world. The decision to use AR Tags definitely constrains the realistic sizes of objects we can manipulate with. Moreover, using hand-mounted cameras, instead of head-mounted or externally mounted, cameras definitely limits the workspace and forces us to be tied to platforms, like Baxter, with hand-mounted cameras. Finally, not allowing Baxter to be cognizant of its environment means that environments would have to be highly controlled and largely static, characteristics that are too idealized compared to the real world.</p>

<h1>
<a id="implementation" class="anchor" href="#implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation</h1>

<p>To complete our project, we used the standard Baxter robotic platform with the suction actuator attachment. We manipulated with toy blocks that were 1.5” cubes and made of wood. On one face of each toy block, we adhered AR Tags to enable Baxter to uniquely identify each block.</p>

<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/tower4.png" alt="AR Tag perception from the hand camera perspective" width="400" height="330" align="middle">
  <figcaption>AR Tag perception from the hand camera perspective</figcaption>
</figure>
</div>

<br>
<p>The <a href="http://www.ros.org/">ROS</a> framework is the software glue that ties all of the hardware together.</p>

<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/software_blockdiagram.png" alt="EE 215A Baxter Tower Project Software Architechure " width="400" height="330" align="middle">
  <figcaption>The software architechure of Baxter Builds a Tower</figcaption>
</figure>
</div>

<ol>
<li>Initialization of AR tracking and MoveIt server as well as robot and camera enabling</li>
<li>Move Baxter’s right arm over toy blocks to localize toy blocks location in the base frame</li>
<li>The publisherMarkerInfo node will publish to found_markers with an array of all markers that were identified</li>
<li>The master node decides which AR Tag to retrieve and computes the transform between the base frame and the AR Tag frame</li>
<li>The translational component of the transform is used by MoveIt as a destination waypoint.
<li>The master node also appends a series of intermediate waypoints to help anchor MoveIt’s trajectory so that the arm moves away from the toy block in the z-direction and approaches the stack of toy blocks from the z-direction </li>
<li>Baxter’s right arm is moved over toy blocks again to get an updated reading of the remaining toy blocks’ location</li>
<li>Steps 4 to 7 are repeated until all blocks have been retrieved and stacked</li>
</ol>

<br>
<p>Baxter's path planning can be seperated into the following step: </p>

<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/left_arm_motion2.png" alt="How Baxter completes the task by its left arm" width="631" height="300" align="middle">
  <figcaption>How Baxter completes the task by its left arm</figcaption>
</figure>
</div>

<ol>
<li>Go to the initial position: In order to avoid the tower collapse, we want Baxter leaves a safe distance from the tower so that its motion would not affect the balance of the tower. Therefore, Baxter goes to the initial position with slow velocity before grasping the new block. </li>
<li>Approach to 10cm above the Target Block: The target pose is acquired from publishMarkerInfo. The desired path can be generated from MoveIt. To make Baxter's motion more efficient, we put some via points in the path to avoid the robot detouring. Also, we increase the robot speed in this segment, since we don't have to worry aobut any object hit by the robot. </li>
<li>Approach to the Target Block: In order to carefully contact on the center of the target, the Baxter uses cautious motion to approach the block.  </li>
<li>Turn on the Suction Actuator: Baxter turns on the vacuum gripper to adhere the block on its end effector.</li>
<li>Move the Block to 10cm above the Destination: The destination is computed from the position of the last block has been placed. Similar to Step 2, we generate some via points and use fast motion to approach the destination. </li>
<li>Approach to Destination: To eliminate the placement offeset and minimize the collapse risk, Baxter use very slow speed to approach the destination.</li>
<li>Turn off the Suction Actuator: Baxter turns off the vacuum gripper to release the block on the desired placement.</li>
<li>Lift 5cm above the Tower: Baxter leaves from the contact point on the tower, and waits for the next iteration.</li>

<h1>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h1>

<p>The video below summarizes our work. Concisely, we successfully:</p>

<ul>
<li>Implemented autonomously tracking and selection of toy blocks, marked by AR Tags</li>
<li>Implemented autonomous path planning between toy block retrieval and placement</li>
<li>Demonstrated an ability to stack toy blocks successively <strong>10</strong> times in a vertical fashion</li>
</ul>

<iframe width="560" height="315" src="//www.youtube.com/embed/q37Nc350ZgY" frameborder="0" allowfullscreen></iframe>

<h1>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h1>

<p>Compared to our original goals, we have completed most of our objectives except the ability to build more complicated structures, such as a house. This can be attributed to Baxter’s intrinsic positional inaccuracy in its arm which hinders its ability to place toy blocks in a structurally stable fashion.</p>

<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/tower5.jpg" alt="AR Tag perception from the hand camera perspective" width="300" height="400" align="middle">
  <figcaption>The relative inaccuracy of Baxter's arm makes for unstable towers</figcaption>
</figure>
</div>
<br>
<p>Moreover, Baxter’s hand-mounted cameras exhibited a fish-eye effect which led to errors in perceiving the location of the AR Tags. This distortion could have been easily fixed by a proper calibration, but Baxter does not readily support such services.</p>

<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/tower6.png" alt="AR Tag perception from the hand camera perspective" width="400" height="330" align="middle">
  <figcaption>The fish eye effect from the hand camera leads to distorted/inaccurate AR Tag reading</figcaption>
</figure>
</div>
<br>
<p>If we had additional time, we would invest in an external camera solution to expand our viewable workspace as well as increase reliability in our sensing through properly calibrated cameras. Plus, we calibrated our robot towards a particular table height (i.e. the Cory 119 table) in order to keep our problem tractable. Future work should include robustness towards a variety of table heights.</p>

<p>For a summary, please see our <a href="http://ucbbaxtertower.github.io/BaxterTower/media/ucbBaxterTower_slides.pdf">slides</a>.</p>

<h1>
<a id="team" class="anchor" href="#team" aria-hidden="true"><span class="octicon octicon-link"></span></a>Team</h1>
<div align="center">
<figure>
  <img src="http://ucbbaxtertower.github.io/BaxterTower/media/group_pic.png" alt="Baxter Tower Group" width="600" height="350" align="middle">
  <figcaption>We are Baxter Tower Group!!</figcaption>
</figure>
</div>


<h3>
<a id="hsien-chung-lin" class="anchor" href="#hsien-chung-lin" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hsien-Chung Lin</h3>

<p><img align="left" hspace="10" src="http://ucbbaxtertower.github.io/BaxterTower/media/person1.jpg" height="150" width="120" alt="Hsien-Chung Lin"></p>
<p>Hsien-Chung Lin is a Mechanical Engineering student from Taiwan. His international student life began in Aug. 2013. Now he is exploring in the robot control research. He is a tall guy and loves playing basketball. He also likes to cook and hangout with friends.</p>
<br>
<br>

<h3>
<a id="te-tang" class="anchor" href="#te-tang" aria-hidden="true"><span class="octicon octicon-link"></span></a>Te Tang</h3>

<p><img align="left" hspace="10" src="http://ucbbaxtertower.github.io/BaxterTower/media/person2.jpg" height="150" width="120" alt="Te Tang"></p>
<p>Te Tang is is a Mechanical Engineering student that loves to cook. He loves to invite people over to hot pot and was heavily involved with the kinematics section of our project.</p>
<br>
<br>

<h3>
<a id="dennis-wai" class="anchor" href="#dennis-wai" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dennis Wai</h3>

<p><img align="left" hspace="10" src="http://ucbbaxtertower.github.io/BaxterTower/media/person3.jpg" height="150" width="120" alt="Dennis Wai"></p>
<p>Dennis Wai is a Mechanical Engineering student that is a little too interested in Electrical Engineering and Computer Science. He likes robots and often can be found volunteering with <a href="pioneers.berkeley.edu">Pioneers in Engineering</a>, a student group focused on delivering robotics experience to underserved Bay Area communities. For this other interests, you can check out his <a href="denniswai.com">website</a>.</p>
<br>
<br>

<h1>
<a id="additional-materials" class="anchor" href="#additional-materials" aria-hidden="true"><span class="octicon octicon-link"></span></a>Additional Materials</h1>

<ul>
<li>Source Code on <a href="https://github.com/ucbBaxterTower/BaxterTower">Github</a>
</li>
<li><a href="http://www.toysrus.com/product/index.jsp?productId=37649076&amp;cp=&amp;parentPage=search">Toy blocks</a></li>
<li><a href="www.ros.org">ROS</a></li>
</ul>
      </section>
      <footer>
        <p>Project maintained by <a href="https://github.com/ucbBaxterTower">ucbBaxterTower</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>